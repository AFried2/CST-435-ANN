{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3dd940f",
   "metadata": {},
   "source": [
    "# **üèÄ Step 1: Project Setup & Data Loading**\n",
    "\n",
    "First, we'll import the necessary libraries and load our dataset. We will then filter the data to create our specific 100-player pool from a 5-year window.\n",
    "\n",
    "**Libraries:**\n",
    "* **pandas & numpy**: For data manipulation.\n",
    "* **scikit-learn**: For data scaling and splitting.\n",
    "* **torch**: For building and training the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07692c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: streamlit in ./.venv/lib/python3.13/site-packages (1.49.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.13/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in ./.venv/lib/python3.13/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in ./.venv/lib/python3.13/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in ./.venv/lib/python3.13/site-packages (from streamlit) (6.2.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./.venv/lib/python3.13/site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: packaging<26,>=20 in ./.venv/lib/python3.13/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in ./.venv/lib/python3.13/site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in ./.venv/lib/python3.13/site-packages (from streamlit) (6.32.1)\n",
      "Requirement already satisfied: pyarrow>=7.0 in ./.venv/lib/python3.13/site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in ./.venv/lib/python3.13/site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in ./.venv/lib/python3.13/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in ./.venv/lib/python3.13/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./.venv/lib/python3.13/site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./.venv/lib/python3.13/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in ./.venv/lib/python3.13/site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./.venv/lib/python3.13/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in ./.venv/lib/python3.13/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.13/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.13/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy torch scikit-learn streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917d02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing season averages for all 562 players in the dataset.\n",
      "------------------------------------------------------------\n",
      "--- Player Pool (First 5 Players with Season Averages) ---\n",
      "          Player        PTS       AST       TRB       STL       BLK       FG%\n",
      "0     A.J. Green   7.659091  1.272727  2.250000  0.545455  0.113636  0.426455\n",
      "1    A.J. Lawson   2.750000  0.000000  0.750000  0.000000  0.000000  0.666750\n",
      "2     AJ Johnson   2.444444  1.222222  1.000000  0.111111  0.000000  0.259333\n",
      "3   Aaron Gordon  12.333333  3.066667  4.733333  0.466667  0.266667  0.510900\n",
      "4  Aaron Holiday   4.222222  1.194444  0.944444  0.361111  0.111111  0.345556\n",
      "\n",
      "--- Scaled Player Pool (First 5 Players) ---\n",
      "          Player       PTS       AST       TRB       STL       BLK       FG%\n",
      "0     A.J. Green  0.236100  0.111888  0.157664  0.183117  0.029260  0.426455\n",
      "1    A.J. Lawson  0.084772  0.000000  0.052555  0.000000  0.000000  0.666750\n",
      "2     AJ Johnson  0.075353  0.107448  0.070073  0.037302  0.000000  0.259333\n",
      "3   Aaron Gordon  0.380189  0.269597  0.331679  0.156667  0.068663  0.510900\n",
      "4  Aaron Holiday  0.130155  0.105006  0.066180  0.121230  0.028609  0.345556\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Load the dataset from the file you provided\n",
    "try:\n",
    "    df = pd.read_csv('database_24_25.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'database_24_25.csv' is in the correct directory.\")\n",
    "    # Fallback dummy data\n",
    "    data = {'Player': [f'Player_{i}' for i in range(200)],\n",
    "            'PTS': np.random.uniform(5, 25, 200), 'AST': np.random.uniform(1, 8, 200),\n",
    "            'TRB': np.random.uniform(2, 12, 200), 'STL': np.random.uniform(0.5, 2, 200),\n",
    "            'BLK': np.random.uniform(0.2, 2, 200), 'FG%': np.random.uniform(0.4, 0.6, 200)}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "# Define the numeric features we want to average\n",
    "features = ['PTS', 'AST', 'TRB', 'STL', 'BLK', 'FG%']\n",
    "\n",
    "# Group by player name and calculate the mean for all numeric stats.\n",
    "# This gives us one row per unique player, representing their season average.\n",
    "player_pool = df.groupby('Player')[features].mean().reset_index()\n",
    "\n",
    "print(f\"Processing season averages for all {len(player_pool)} players in the dataset.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Normalize the features to a scale of 0-1.\n",
    "scaler = MinMaxScaler()\n",
    "player_pool_scaled = player_pool.copy()\n",
    "player_pool_scaled[features] = scaler.fit_transform(player_pool_scaled[features])\n",
    "\n",
    "print(\"--- Player Pool (First 5 Players with Season Averages) ---\")\n",
    "# The stats you see now are the averages for each player\n",
    "print(player_pool.head())\n",
    "print(\"\\n--- Scaled Player Pool (First 5 Players) ---\")\n",
    "print(player_pool_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25941cb1",
   "metadata": {},
   "source": [
    "# **üß™ Step 2: Defining \"Optimal\" & Generating Training Data**\n",
    "\n",
    "An ANN needs a clear target to predict. We will define an \"optimal team\" by creating a **Team Score**. The model's job is to learn how to predict this score.\n",
    "\n",
    "**Our Team Score Formula:**\n",
    "$TeamScore = Offense + Defense - ImbalancePenalty$\n",
    "\n",
    "We will then generate thousands of random 5-player teams, calculate their aggregated stats (our `X`), and their `Team Score` (our `y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7dd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 50000 training samples.\n",
      "Shape of X_train: (40000, 6)\n",
      "Shape of y_train: (40000,)\n"
     ]
    }
   ],
   "source": [
    "def calculate_team_score(team_df):\n",
    "    \"\"\"Calculates a custom score for a 5-player team.\"\"\"\n",
    "    # Using the updated features list which includes 'TRB'\n",
    "    stats = team_df[features].sum()\n",
    "\n",
    "    # 1. Offensive Rating (weighted sum, now using TRB for rebounds)\n",
    "    offense_score = (stats['PTS'] * 0.4) + (stats['AST'] * 0.3) + (stats['TRB'] * 0.1) + (stats['FG%'] * 0.2)\n",
    "\n",
    "    # 2. Defensive Rating\n",
    "    defense_score = (stats['STL'] * 0.5) + (stats['BLK'] * 0.5)\n",
    "\n",
    "    # 3. Positional Imbalance Penalty\n",
    "    penalty = 0\n",
    "    if 'Pos' in team_df.columns:\n",
    "        pos_counts = team_df['Pos'].value_counts()\n",
    "        guards = pos_counts.get('G', 0)\n",
    "        forwards = pos_counts.get('F', 0)\n",
    "        centers = pos_counts.get('C', 0)\n",
    "        penalty = abs(guards - 2) + abs(forwards - 2) + abs(centers - 1)\n",
    "\n",
    "    # Final Score\n",
    "    final_score = (offense_score * 0.6) + (defense_score * 0.4) - (penalty * 0.1)\n",
    "    return final_score\n",
    "\n",
    "# Generate 50,000 random teams to create our training dataset\n",
    "num_combinations = 50000\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for _ in range(num_combinations):\n",
    "    # Select 5 random players from our scaled pool\n",
    "    team_indices = np.random.choice(player_pool_scaled.index, 5, replace=False)\n",
    "    team_df_scaled = player_pool_scaled.loc[team_indices]\n",
    "\n",
    "    # The input (X) is the sum of the team's scaled stats\n",
    "    team_stats_vector = team_df_scaled[features].sum().values\n",
    "    X_data.append(team_stats_vector)\n",
    "\n",
    "    # The label (y) is the team's score, calculated from the original, unscaled data\n",
    "    team_df_original = player_pool.loc[team_indices]\n",
    "    team_score = calculate_team_score(team_df_original)\n",
    "    y_data.append(team_score)\n",
    "\n",
    "X = np.array(X_data)\n",
    "y = np.array(y_data)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Generated {len(X)} training samples.\")\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06e399e",
   "metadata": {},
   "source": [
    "# **ü§ñ Step 3: Build and Train the Artificial Neural Network (PyTorch)**\n",
    "\n",
    "We'll now define our Multilayer Perceptron (MLP) architecture and training loop using PyTorch.\n",
    "\n",
    "* **Model**: Two hidden layers with `ReLU` activation and a `Dropout` layer to prevent overfitting.\n",
    "* **Loss Function**: `MSELoss` (Mean Squared Error), ideal for regression.\n",
    "* **Optimizer**: `Adam`, a standard and effective optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa00f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyTorch model training...\n",
      "Epoch [10/50], Loss: 4.6111, Test Loss: 0.1109\n",
      "Epoch [20/50], Loss: 1.8406, Test Loss: 0.0045\n",
      "Epoch [30/50], Loss: 0.2630, Test Loss: 0.0475\n",
      "Epoch [40/50], Loss: 0.2788, Test Loss: 0.0245\n",
      "Epoch [50/50], Loss: 0.2375, Test Loss: 0.0260\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. PyTorch Model Definition ---\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# --- 2. PyTorch Training Loop ---\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=50, batch_size=32):\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    print(\"Starting PyTorch model training...\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        permutation = torch.randperm(X_train_tensor.size()[0])\n",
    "        \n",
    "        for i in range(0, X_train_tensor.size()[0], batch_size):\n",
    "            optimizer.zero_grad()\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_X, batch_y = X_train_tensor[indices], y_train_tensor[indices]\n",
    "            y_pred = model(batch_X)\n",
    "            loss = loss_function(y_pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_pred = model(X_test_tensor)\n",
    "                test_loss = loss_function(test_pred, y_test_tensor)\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}')\n",
    "    \n",
    "    print(\"Training complete.\")\n",
    "    return model\n",
    "\n",
    "# --- 3. Instantiate and Train the Model ---\n",
    "input_size = X_train.shape[1]\n",
    "pytorch_model = MLP(input_size)\n",
    "\n",
    "trained_model = train_model(pytorch_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd87c9",
   "metadata": {},
   "source": [
    "# **üèÜ Step 4: Find the Optimal Team**\n",
    "\n",
    "With our trained model, we can now search for the best team. Since checking every single combination is too slow, we'll test a large number of random combinations and use the model to predict the score for each one. The team with the highest predicted score is our winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "309d1c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for the optimal team by testing 200,000 combinations...\n",
      "\n",
      "--- üèÜ Optimal Team Found ---\n",
      "Predicted Team Score: 37.58\n",
      "\n",
      "              Player        PTS       AST       TRB       STL       BLK\n",
      "31   Anthony Edwards  27.215686  4.529412  5.784314  1.137255  0.686275\n",
      "249    Jaren Jackson  21.612903  1.774194  5.935484  1.451613  1.709677\n",
      "330     Kevin Durant  26.923077  4.179487  6.076923  0.820513  1.333333\n",
      "530      Tyler Herro  23.734694  5.551020  5.571429  0.734694  0.122449\n",
      "364      Luka Donƒçiƒá  28.136364  7.818182  8.318182  2.000000  0.409091\n"
     ]
    }
   ],
   "source": [
    "print(\"Searching for the optimal team by testing 200,000 combinations...\")\n",
    "\n",
    "best_team_indices = None\n",
    "best_predicted_score = -np.inf\n",
    "search_space_size = 200000\n",
    "\n",
    "player_ids = player_pool.index.to_numpy()\n",
    "\n",
    "# Set the model to evaluation mode (important for dropout layers)\n",
    "trained_model.eval()\n",
    "\n",
    "for _ in range(search_space_size):\n",
    "    # 1. Pick a random 5-player team\n",
    "    team_indices = np.random.choice(player_ids, 5, replace=False)\n",
    "    team_df_scaled = player_pool_scaled.loc[team_indices]\n",
    "\n",
    "    # 2. Prepare the input vector for the model\n",
    "    input_vector = team_df_scaled[features].sum().values\n",
    "    \n",
    "    # 3. Use the model to predict the score (with PyTorch syntax)\n",
    "    with torch.no_grad(): # Disable gradient calculation for inference\n",
    "        input_tensor = torch.tensor(input_vector, dtype=torch.float32).view(1, -1)\n",
    "        predicted_score = trained_model(input_tensor).item()\n",
    "\n",
    "    # 4. If this team is the best so far, save it\n",
    "    if predicted_score > best_predicted_score:\n",
    "        best_predicted_score = predicted_score\n",
    "        best_team_indices = team_indices\n",
    "\n",
    "# Retrieve the optimal team's details from the original (unscaled) dataframe\n",
    "optimal_team = player_pool.loc[best_team_indices]\n",
    "\n",
    "print(\"\\n--- üèÜ Optimal Team Found ---\")\n",
    "print(f\"Predicted Team Score: {best_predicted_score:.2f}\\n\")\n",
    "print(optimal_team[['Player', 'PTS', 'AST', 'TRB', 'STL', 'BLK']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
